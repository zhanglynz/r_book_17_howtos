[["index.html", "R tips: 17 HOWTO's with examples for data analysts", " R tips: 17 HOWTO's with examples for data analysts Lingyun Zhang 2019-03-23 "],["preface.html", "Preface", " Preface This is my second book that is related to R; my first one is still under review for publication. Based on my experiences on reading many books and writing a book, I think from Preface readers should have answers to these questions: What is the book about? What are the features of the book? Who are the intended readers? How to read the book? What is the background of the author? So, let me answer these questions here. This book includes 16 R tips, such as &quot;how to explore a 'new' data set&quot; (Chapter 3), &quot;how to create contingency tables&quot; (Chapter 7), &quot;how to tally&quot; (Chapter 8), &quot;how to join two data tables&quot; (Chapter 9), &quot;how to plot data&quot; (Chapter 10), &quot;how to create a dynamic report&quot; (Chapter 11), &quot;how to learn Shiny&quot; (Chapter 12), &quot;how to check code efficiency&quot; (Chapter 14), .... These are all very much practically useful for a data analyst in his/her daily work. This book gives detailed examples and uses fake data. Indeed, these are two features of the book. You may ask: &quot;Why fake data, does it sound bad?&quot; I do not care if it sounds bad. The reasons for using fake data are: (a) Fake data make reader's life easier, because they are easy to be understood and they serve the purpose for helping the reader quickly grasp the concepts and techniques. (b) Fake data make my writing easier -- this is obvious. The cover of this book shows office buildings, and this book is directly for those data analysts who work in buildings like these ones and are doing official statistics, e.g. data analysis and reporting. Indirectly, this book is also for the other data analysts; they may more or less get something useful from this book. The presumed level of R knowledge of the intended readers is beginner or advanced beginner. How to read this book? My suggestion is that firstly read the description at the beginning of each chapter and then read the R code. By &quot;read the R code&quot;, I mean the reader can try to mentally understand the code and then run the code in R to check if you get the expected results. I wrote this book in my spare time (a couple of hours after dinner on work days and weekends). I did this because during my work I had solved some specific problems and after dinner when I digest--not food but--the solutions that I got I often had an urge to generalise the solutions. This is why I wrote this book. I have written down the solutions for the future me and also want to share them with you. Short biography: I was born in China and grew up there. I earned a Ph.D. in Mathematical Statistics from the University of Regina, Canada. To see my publications, here is the link to my Google Scholar web page. I used to be in academia and changed to government jobs since 2016. Acknowledgements: I want to thank three ex-colleagues. Eric Wu was my buddy, and I thank him for answering my heaps of R questions. Peter Ellis works very hard even in after hours (http://ellisp.github.io/); he motivated me to work hard. James Hogan, thank you so much for your encouragement and help when I was in a difficult time, and I would never forget about the chocolates and cake. Special thanks to those who created the great R packages; special thanks to RStudio Inc., from which R users all over the world have tremendously benefited. License: This work by Lingyun Zhang is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License "],["how-to-organize-a-project-folder.html", "1 How to organize a project folder", " 1 How to organize a project folder It is exciting when we will start a new project. At the beginning, we should make things right! By that I mean we must organize our project folder properly. Here are the steps for creating a sample project: Create a folder with a meaningful name for the project. In RStudio: File &gt; New Project &gt; Existing Directory &gt; Browse &gt; The folder just created &gt; Select Folder &gt; Create Project, this will result in a file with extension .Rproj Create two subfolders, R (which will contain R scripts) and Data (which will contain data sets) in the project folder. Create other subfolders, such as Image (which will contain graphs/pictures), if this is necessary. In the project folder, create other files, e.g. files for version control. In the project folder, after we have written R programs and saved them in the R folder, we create a file called integrate.R, which is an R script that integrates all the R programs in the R folder. In the above, Steps 1, 2, 3 and 6 are the must. A minimal example is shown below. The structure of the project folder: The integrate.R script: # Please run the R programs in order source(&quot;./R/temp1.R&quot;) source(&quot;./R/create_a_plot.R&quot;) source(&quot;./R/create_a_table.R&quot;) Note that &quot;.&quot; (the dot) is for the root directory (i.e. the project folder). So, here we use a relative path instead of an absolute one. This is a good practice, because if other people copy/clone this project they will put the project folder under a parent folder with a name different from mine. "],["how-to-read-data-into-r.html", "2 How to read data into R", " 2 How to read data into R Reading data into R seems to be straightforward, but &quot;the devil is in the detail.&quot; Indeed, we must pay attention to some fine points when use R functions to read data. Firstly, I make a summary table, which shows the most useful R functions for data import. import file type, or from R function .txt read.table() .csv read.csv() and readr::read_csv() .xls and .xlsx readxl::read_excel() and openxlsx::read.xlsx() .sav foreign::read.spss() .Rdata or rda load() .rds readRDS() and readr::read_rds() Internet download.file() Secondly, the fine points. Before reading a .txt file, it is a good idea that we open the file with Notepad++ and look at the encoding by clicking on the Encoding tab. If necessary, we can convert the encoding to &quot;UTF-8&quot;, and use read.table(..., fileEncoding = &quot;UTF-8&quot;). When we are dealing with large data, we'd better use readr::read_csv() rather than read.csv() because the former is much faster. It is good practice that we firstly open the file with Excel and spend some time understanding the types of variables. If it is not too troublesome, we should specify the types of variables, e.g. readr::read_csv(..., col_types = &quot;iDdccciccllc&quot;). &quot;load() replaces all existing objects with the same names in the current environment (typically your workspace, .GlobalEnv) and hence potentially overwrites important data.&quot; (R Help) So, if we use load() we should put it at the beginning. A really useful small tip: type file.choose() into R console and then navigate until you find the file and click on Open; in such a way you can quickly know the absolute path of the file that you want to read into R. Thirdly, examples: my_data &lt;- read.table(file= &quot;./data/SevenSurgeons.txt&quot;, header = TRUE) load(file = &quot;./data/CDS_all.rda&quot;) file_infor &lt;- readRDS(file = &quot;./data/f_infor.rds&quot;) library(readr) file_name &lt;- &quot;./data/export.csv&quot; my_data &lt;- read_csv(file = file_name, locale = locale(), skip = 1) the_url &lt;- &quot;https://raw.githubusercontent.com/LarryZhang2016/Data/master/NZ_cities.csv&quot; NZ_cities &lt;- read_csv(the_url, skip =1) library(readxl) month_and_year &lt;- &quot;July2016&quot; raw_data_file_name &lt;- paste0(&quot;./RawData/&quot;, &quot;raw_data_&quot;, month_and_year, &quot;.xlsx&quot;) raw_data &lt;- read_excel(path = raw_data_file_name, sheet = &quot;Very_raw_data&quot;, skip = 0, col_names = TRUE) "],["how-to-explore-a-new-data-set.html", "3 How to explore a &quot;new&quot; data set", " 3 How to explore a &quot;new&quot; data set By a &quot;new&quot; data set, I mean it is new to us, that is, we have never seen it before. To explore this new data set, we can follow these steps. Read the data into R. Find the dimensions of this data set by using dim(). Understand the structure of the data by using str(). See the first 6 rows of the data using head(); see the last 6 rows of the data using tail(). Find out the names of all the (column) variables in the data set. Pay attention to the variable with &quot;ID&quot; (or &quot;id&quot;) as part of its name, since this variable will be used when we want to join this data set with another one. Figure out the variables that of interest by reading the names. If the interesting variable is of categorical type, then use unique() to find out all the possible values that the variable can take. If the interesting variable is of continuous type, then use summary() to look at the 5-number summary. Use View() to have a quick look at the whole data set. Example: rm(list=ls()) # Firstly, we must read data into R # Here I will use fake data fk_data &lt;- data.frame(ob_id = 1:100, l_lower_case = sample(letters, 100, replace = TRUE), rand_number = rnorm(100), l_upper_case = sample(LETTERS, 100, replace = TRUE), true_or_false = sample(c(&quot;T&quot;, &quot;F&quot;), 100, replace = TRUE) ) # Find the dimensions d &lt;- dim(fk_data) # Find the structure str(fk_data) # See the first 6 rows head(fk_data) # See the last 6 rows tail(fk_data) # Find the column names the_names &lt;- names(fk_data) # Find possible values of &quot;l_lower_case&quot; possible_values &lt;- unique(fk_data$l_lower_case) # Find summary of &quot;rand_number&quot; the_summary &lt;- summary(fk_data$rand_number) # View the data set View(fk_data) "],["how-to-deal-with-nas.html", "4 How to deal with NA's", " 4 How to deal with NA's &quot;NA&quot; stands for &quot;Not Available&quot;, or it means &quot;missing value&quot;. These R functions are useful to deal with NA's, is.na(), na.omit(), complete.cases(), colSums(), rowSums(), tidyr::replace_na() and dplyr::na_if(). Example: rm(list=ls()) # load packages library(dplyr) # for na.if library(tidyr) # for replace_na # create a fake data set fk_data &lt;- data.frame(v1 = 1:5, v2 = c(1, 3, NA, 8, -99), v3 = c(NA, NA, rnorm(3))) # which variables have NA&#39;s and how many NA&#39;s colSums(is.na(fk_data)) # which rows have NA&#39;s and how many NA&#39;s rowSums(is.na(fk_data)) # get all the rows which have NA&#39;s fk_data_na_rows &lt;- fk_data[rowSums(is.na(fk_data)) &gt; 0, ] # get all the rows which do not have NA&#39;s fk_data_without_na_rows &lt;- fk_data[rowSums(is.na(fk_data)) == 0, ] # or fk_data_without_na_rows &lt;- fk_data[complete.cases(fk_data) == TRUE, ] # or fk_data_without_na_rows &lt;- na.omit(fk_data) # replace all the NA&#39;s with 0 fk_data_replace &lt;- fk_data fk_data_replace[is.na(fk_data_replace)] &lt;- 0 # or directly fk_data[is.na(fk_data)] &lt;- 0, if we don&#39;t need fk_data anymore # replace NA in v3 with 1 fk_data_replace &lt;- fk_data %&gt;% replace_na(list(v3 = 1)) # replace -99 in fk_data by NA fk_data_1 &lt;- na_if(fk_data, -99) # find the mean of v2 in fk_data the_mean &lt;- mean(fk_data$v2, na.rm = TRUE) "],["how-to-deal-with-empty-spaces.html", "5 How to deal with empty spaces 5.1 Empty spaces in variable names 5.2 Empty spaces in variable values", " 5 How to deal with empty spaces Warning: Empty spaces in (column) variable names or in variables often cause troubles! 5.1 Empty spaces in variable names After reading data into R, we should have the habit of using names() (or colnames()) to have a look at all the names of the column names. If we find some column names have empty spaces, then we should pay attention to and even do something about that. Let me explain with an example. Example: rm(list=ls()) # load packages library(ggplot2) # Create a dataframe set.seed &lt;- 12345 fk_data &lt;- data.frame(Year = rep(2011:2015, each = 4), AvgScore = round(rnorm(20, mean=50, sd=5), 0), Gender = rep(c(&quot;Male&quot;, &quot;Female&quot;), 10)) # An extra variable fk_data$&quot;Subject &quot; &lt;- rep( c(rep(&quot;Maths&quot;, 2), rep(&quot;Stats&quot;, 2)), 5 ) # Make a plot ggplot(fk_data, aes(x = Year, y = AvgScore, group = Gender, colour = Gender)) + geom_point() + geom_line() + facet_grid( . ~ Subject ) # The above plotting does not work # What about the following ggplot(fk_data, aes(x = Year, y = AvgScore, group = Gender, colour = Gender)) + geom_point() + geom_line() + facet_grid( . ~ &quot;Subject &quot; ) # It does not work either # The first fix # We don&#39;t remove the space in &quot;Subject &quot; ggplot(fk_data, aes(x = Year, y = AvgScore, group = Gender, colour = Gender)) + geom_point() + geom_line() + facet_grid( . ~ `Subject ` ) # backticks! It works fine here. # Thanks to http://stackoverflow.com/questions/4551424/how-to-refer-to-a-variable-name-with-spaces # The second fix. # We remove the space in &quot;Subject &quot; fk_data$Subject &lt;- fk_data$&quot;Subject &quot; # create a new column/variable fk_data$&quot;Subject &quot; &lt;- NULL # remove the column # Now make the plot ggplot(fk_data, aes(x = Year, y = AvgScore, group = Gender, colour = Gender)) + geom_point() + geom_line() + facet_grid( . ~ Subject ) 5.2 Empty spaces in variable values Sometimes we may encounter a variable with its values containing empty spaces at the beginning or at the end or both, and almost certainly we should remove these spaces. Fortunately, it is easy to do so with stringr::str_trim() or trimws(). Example 1: rm(list=ls()) # load packages library(stringr) library(dplyr) # create a dataframe fk_data &lt;- data.frame(student_no = 1:4, major = c(&quot;maths&quot;, &quot; English&quot;, &quot; maths &quot;, &quot;English &quot;)) # find the number of students majored in maths (no_of_maths_majored_students &lt;- sum(fk_data$major == &quot;maths&quot;)) # this does not give the right answer # fix: remove the spaces no_of_students_by_major &lt;- fk_data %&gt;% mutate(major = str_trim(fk_data$major, side = &quot;both&quot;)) %&gt;% group_by(major) %&gt;% summarise(count = n()) Example 2: Removing leading/trailing and in-between spaces (x &lt;- &quot; a big space problem &quot;) ## [1] &quot; a big space problem &quot; # firstly remove leading and trailing spaces (y &lt;- trimws(x)) ## [1] &quot;a big space problem&quot; # secondly remove &#39;extra&#39; spaces in between # thanks to https://stackoverflow.com/questions/19128327/how-to-remove-extra-white-space-between-words-inside-a-character-vector-using (z &lt;- gsub(&quot;\\\\s+&quot;,&quot; &quot;, y)) ## [1] &quot;a big space problem&quot; "],["how-to-do-simple-re-coding.html", "6 How to do simple re-coding", " 6 How to do simple re-coding At work, sometimes we may need to recode a categorical variable to another one according to some mapping rules. This is the so-called &quot;re-coding&quot;. Below is an R function that I write for recording. simple_recoding &lt;- function(v, from, to, mapping_rule_data = NULL) {L &lt;- length(v) N &lt;- length(to) if(is.null(mapping_rule_data) == TRUE) {mapping_rule &lt;- matrix(rep(1:N, each = 2), N, 2, byrow = TRUE)} else {mapping_rule &lt;- matrix(mapping_rule_data, N, 2, byrow = TRUE)} the_result &lt;- rep(&quot;&quot;, L) for(i in 1:L) for(j in 1:N) {a &lt;- mapping_rule[j, 1] b &lt;- mapping_rule[j, 2] if(v[i] %in% from[a : b]) the_result[i] &lt;- to[j] } return(the_result) } Let me use two examples to explain. Example 1: (x &lt;- sample(letters, 30, replace = TRUE)) ## [1] &quot;m&quot; &quot;j&quot; &quot;h&quot; &quot;m&quot; &quot;l&quot; &quot;w&quot; &quot;i&quot; &quot;e&quot; &quot;z&quot; &quot;o&quot; &quot;x&quot; &quot;i&quot; &quot;s&quot; &quot;k&quot; &quot;f&quot; &quot;a&quot; &quot;l&quot; &quot;h&quot; &quot;t&quot; ## [20] &quot;s&quot; &quot;p&quot; &quot;w&quot; &quot;y&quot; &quot;r&quot; &quot;e&quot; &quot;l&quot; &quot;q&quot; &quot;s&quot; &quot;d&quot; &quot;k&quot; We want to re-code x to y, where x has lowercase letters and y has the corresponding uppercase letters. In this case. from = letters and to = LETTERS We can use the default mapping_rule_data = NULL since this is a one-to-one mapping. (y &lt;- simple_recoding(x, from = letters, to = LETTERS)) ## [1] &quot;M&quot; &quot;J&quot; &quot;H&quot; &quot;M&quot; &quot;L&quot; &quot;W&quot; &quot;I&quot; &quot;E&quot; &quot;Z&quot; &quot;O&quot; &quot;X&quot; &quot;I&quot; &quot;S&quot; &quot;K&quot; &quot;F&quot; &quot;A&quot; &quot;L&quot; &quot;H&quot; &quot;T&quot; ## [20] &quot;S&quot; &quot;P&quot; &quot;W&quot; &quot;Y&quot; &quot;R&quot; &quot;E&quot; &quot;L&quot; &quot;Q&quot; &quot;S&quot; &quot;D&quot; &quot;K&quot; Example 2: (u &lt;- sample(letters, 30, replace = TRUE)) ## [1] &quot;l&quot; &quot;f&quot; &quot;k&quot; &quot;b&quot; &quot;z&quot; &quot;w&quot; &quot;o&quot; &quot;q&quot; &quot;c&quot; &quot;l&quot; &quot;o&quot; &quot;z&quot; &quot;u&quot; &quot;h&quot; &quot;h&quot; &quot;x&quot; &quot;x&quot; &quot;o&quot; &quot;v&quot; ## [20] &quot;z&quot; &quot;o&quot; &quot;n&quot; &quot;q&quot; &quot;q&quot; &quot;x&quot; &quot;p&quot; &quot;b&quot; &quot;s&quot; &quot;x&quot; &quot;i&quot; We want to re-code u to w, where the mapping rule is as follows. \\[ \\begin{array}{ccc} \\left\\{\\hbox{a, b, c, d, e}\\right\\} &amp;\\longrightarrow &amp; \\left\\{\\hbox{A}\\right\\}\\\\ \\left\\{\\hbox{f, g, h, i, j}\\right\\} &amp;\\longrightarrow &amp; \\left\\{\\hbox{B}\\right\\}\\\\ \\left\\{\\hbox{k, l, m, n, o}\\right\\} &amp;\\longrightarrow &amp; \\left\\{\\hbox{C}\\right\\}\\\\ \\left\\{\\hbox{p, q, r, s, t}\\right\\} &amp;\\longrightarrow&amp; \\left\\{\\hbox{D}\\right\\}\\\\ \\left\\{\\hbox{u, v, w, x, y}\\right\\} &amp;\\longrightarrow&amp; \\left\\{\\hbox{E}\\right\\}\\\\ \\left\\{\\hbox{z}\\right\\} &amp;\\longrightarrow&amp; \\left\\{\\hbox{Z}\\right\\} \\end{array} \\] In this case, from = letters and to = c(LETTERS[1:5], &quot;Z&quot;) But note that mapping_rule_data = c(1, 5, 6, 10, 11, 15, 16, 20, 21, 25, 26, 26 ) because letters[1:5] are mapped to &quot;A&quot;, letters[6:10] are mapped to &quot;B&quot;, and so on. (simple_recoding(u, from = letters, to = c(LETTERS[1:5], &quot;Z&quot;), mapping_rule_data = c(1, 5, 6, 10, 11, 15, 16, 20, 21, 25, 26, 26 ))) ## [1] &quot;C&quot; &quot;B&quot; &quot;C&quot; &quot;A&quot; &quot;Z&quot; &quot;E&quot; &quot;C&quot; &quot;D&quot; &quot;A&quot; &quot;C&quot; &quot;C&quot; &quot;Z&quot; &quot;E&quot; &quot;B&quot; &quot;B&quot; &quot;E&quot; &quot;E&quot; &quot;C&quot; &quot;E&quot; ## [20] &quot;Z&quot; &quot;C&quot; &quot;C&quot; &quot;D&quot; &quot;D&quot; &quot;E&quot; &quot;D&quot; &quot;A&quot; &quot;D&quot; &quot;E&quot; &quot;B&quot; Exercise: fk_data &lt;- data.frame(my_colors = c(&quot;red&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;green&quot;, &quot;blue&quot;)) Create a new variable called &quot;RGB&quot; following the mapping rules \\[ \\begin{array}{ccc} \\left\\{\\hbox{red, orange, yellow}\\right\\} &amp;\\longrightarrow&amp; \\left\\{\\hbox{R}\\right\\}\\\\ \\left\\{\\hbox{green}\\right\\} &amp;\\longrightarrow&amp; \\left\\{\\hbox{G}\\right\\}\\\\ \\left\\{\\hbox{blue}\\right\\} &amp;\\longrightarrow&amp; \\left\\{\\hbox{B}\\right\\} \\end{array} \\] Answer to the Exercise: rm(list = ls()) # load package library(dplyr) source(&quot;simple_recoding.R&quot;) # create a fake data set fk_data &lt;- data.frame(my_colors = c(&quot;red&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;green&quot;, &quot;blue&quot;)) fk_data_1 &lt;- fk_data %&gt;% mutate(RGB = simple_recoding(my_colors, from = my_colors, to = c(&quot;R&quot;, &quot;G&quot;, &quot;B&quot;), mapping_rule_data = c(1, 3, 4, 4, 5, 5))) "],["how-to-create-contingency-tables.html", "7 How to create contingency tables", " 7 How to create contingency tables We can use table(), addmargins(), prop.table() and as.data.frame.matrix() to create the contingency tables that we want. See this example: rm(list=ls()) # load packages library(dplyr) # create a fake data set fk_data &lt;- data.frame(x1 = sample(letters[1:5], 20, replace = TRUE), x2 = sample(LETTERS[1:5], 20, replace = TRUE)) # have a look at the data set print.data.frame(fk_data) ## x1 x2 ## 1 c E ## 2 d C ## 3 d A ## 4 e B ## 5 d A ## 6 d A ## 7 c C ## 8 d B ## 9 a C ## 10 b A ## 11 b B ## 12 a E ## 13 c A ## 14 a A ## 15 d D ## 16 e C ## 17 d D ## 18 d D ## 19 e E ## 20 a D # create a table my_table_0 &lt;- table(fk_data$x1, fk_data$x2) print.table(my_table_0) ## ## A B C D E ## a 1 0 1 1 1 ## b 1 1 0 0 0 ## c 1 0 1 0 1 ## d 3 1 1 3 0 ## e 0 1 1 0 1 # if we want to have row and column totals my_table_01 &lt;- addmargins(my_table_0) print.table(my_table_01) ## ## A B C D E Sum ## a 1 0 1 1 1 4 ## b 1 1 0 0 0 2 ## c 1 0 1 0 1 3 ## d 3 1 1 3 0 8 ## e 0 1 1 0 1 3 ## Sum 6 3 4 4 3 20 my_table_1 &lt;- as.data.frame.matrix(my_table_0) # convert it to dataframe # have a look at the table print.data.frame(my_table_1) ## A B C D E ## a 1 0 1 1 1 ## b 1 1 0 0 0 ## c 1 0 1 0 1 ## d 3 1 1 3 0 ## e 0 1 1 0 1 # to have a table of proportions based on rows my_table_2 &lt;- prop.table(my_table_0, margin = 1) %&gt;% as.data.frame.matrix() # convert it to dataframe # have a look at the table print.data.frame(my_table_2, digits = 2) ## A B C D E ## a 0.25 0.00 0.25 0.25 0.25 ## b 0.50 0.50 0.00 0.00 0.00 ## c 0.33 0.00 0.33 0.00 0.33 ## d 0.38 0.12 0.12 0.38 0.00 ## e 0.00 0.33 0.33 0.00 0.33 # to have a table of proportions based on columns my_table_3 &lt;- prop.table(my_table_0, margin = 2) %&gt;% as.data.frame.matrix() # convert it to dataframe # have a look at the table print.data.frame(my_table_3, digits = 2) ## A B C D E ## a 0.17 0.00 0.25 0.25 0.33 ## b 0.17 0.33 0.00 0.00 0.00 ## c 0.17 0.00 0.25 0.00 0.33 ## d 0.50 0.33 0.25 0.75 0.00 ## e 0.00 0.33 0.25 0.00 0.33 Remark: If there are NA's, table() function will ignore them. If we want to include NA's in the table, we can use dplyr::tally() plus tidyr::spread(); the following example shows how to do this. For more details about dplyr::tally(), see the next chapter, How to tally. rm(list = ls()) # load packages library(dplyr) library(tidyr) # for spread() # create a fake data set fk_data &lt;- data.frame(category_1 = c(rep(&quot;A&quot;, 3), &quot;B&quot;, rep(&quot;C&quot;, 2), NA, NA), category_2 = c(rep(&quot;a&quot;, 2), rep(&quot;b&quot;, 2), rep(NA, 3), &quot;c&quot;)) # show the tale created by using table() print.table(table(fk_data$category_1, fk_data$category_2)) ## ## a b c ## A 2 1 0 ## B 0 1 0 ## C 0 0 0 # create a contingency table using dplyr::tally and tidyr::spread a_table &lt;- fk_data %&gt;% group_by(category_1, category_2) %&gt;% tally() %&gt;% spread(key = category_2, value = n) print.data.frame(a_table) ## category_1 a b c &lt;NA&gt; ## 1 A 2 1 NA NA ## 2 B NA 1 NA NA ## 3 C NA NA NA 2 ## 4 &lt;NA&gt; NA NA 1 1 "],["how-to-tally.html", "8 How to tally", " 8 How to tally As data analysts, we must know how to tally data. For tallying one or two variables, we can use function table() plus other helper functions as shown in the previous chapter. Here, we will learn how to do the job for \\(n\\) variables (where \\(n\\ge 1\\)) using dplyr package. Example 1 rm(list = ls()) # load packages library(dplyr) library(tidyr) # for replace_na() set.seed(28072017) # create a fake data prob_1 &lt;- c(0.2, 0.5, 0.3) prob_2 &lt;- c(0.3, 0.7) set_1 &lt;- c(&quot;long&quot;, &quot;medium&quot;, &quot;short&quot;) set_2 &lt;- c(&quot;heavy&quot;, &quot;light&quot;) set_3 &lt;- c(&quot;red&quot;, &quot;yellow&quot;, &quot;green&quot;) fk_data &lt;- data.frame(size = sample(set_1, 20, replace = TRUE, prob = prob_1), weight = sample(set_2, 20, replace = TRUE, prob = prob_2), color = sample(set_3, 20, replace = TRUE)) # tally one variable tally_1 &lt;- fk_data %&gt;% group_by(color) %&gt;% tally() print.data.frame(tally_1) ## color n ## 1 green 8 ## 2 red 7 ## 3 yellow 5 # tally two varaibles tally_2 &lt;- fk_data %&gt;% group_by(size, weight) %&gt;% tally() print.data.frame(tally_2) ## size weight n ## 1 long heavy 1 ## 2 long light 3 ## 3 medium heavy 4 ## 4 medium light 6 ## 5 short heavy 2 ## 6 short light 4 # tally three variables tally_3 &lt;- fk_data %&gt;% group_by(size, weight, color) %&gt;% tally() %&gt;% arrange(size, weight, color) print.data.frame(tally_3) ## size weight color n ## 1 long heavy yellow 1 ## 2 long light green 1 ## 3 long light red 1 ## 4 long light yellow 1 ## 5 medium heavy green 3 ## 6 medium heavy yellow 1 ## 7 medium light green 2 ## 8 medium light red 3 ## 9 medium light yellow 1 ## 10 short heavy green 1 ## 11 short heavy red 1 ## 12 short light green 1 ## 13 short light red 2 ## 14 short light yellow 1 # The following is to refine tally3 # to show all combinations of levels of the three factors # Step a: to have a dataframe which has # all the level combinations levels_comb_df &lt;- expand.grid(size = levels(fk_data$size), weight = levels(fk_data$weight), color = levels(fk_data$color)) # Step b: create tally4 by join # Notice the difference between tally3 and tally 4 tally_4 &lt;- levels_comb_df %&gt;% left_join(tally_3, by =c(&quot;size&quot; = &quot;size&quot;, &quot;weight&quot; = &quot;weight&quot;, &quot;color&quot; = &quot;color&quot;)) %&gt;% # replace na by 0 replace_na(list(n=0)) %&gt;% arrange(size, weight, color) print.data.frame(tally_4) ## size weight color n ## 1 long heavy green 0 ## 2 long heavy red 0 ## 3 long heavy yellow 1 ## 4 long light green 1 ## 5 long light red 1 ## 6 long light yellow 1 ## 7 medium heavy green 3 ## 8 medium heavy red 0 ## 9 medium heavy yellow 1 ## 10 medium light green 2 ## 11 medium light red 3 ## 12 medium light yellow 1 ## 13 short heavy green 1 ## 14 short heavy red 1 ## 15 short heavy yellow 0 ## 16 short light green 1 ## 17 short light red 2 ## 18 short light yellow 1 Using the same fake data as that of Example 1, in Example 2, we show how to find the number of distinct weight-color combinations for each of the &quot;long&quot;, &quot;medium&quot; and &quot;short&quot; subgroups. At work, sometimes we need to deal with this kind of problems. The solution comes from https://stackoverflow.com/questions/43690920/count-subgroups-in-group-by-with-dplyr Example 2 rm(list = ls()) # load packages library(dplyr) library(tidyr) # for replace_na() set.seed(28072017) # create a fake data prob_1 &lt;- c(0.2, 0.5, 0.3) prob_2 &lt;- c(0.3, 0.7) set_1 &lt;- c(&quot;long&quot;, &quot;medium&quot;, &quot;short&quot;) set_2 &lt;- c(&quot;heavy&quot;, &quot;light&quot;) set_3 &lt;- c(&quot;red&quot;, &quot;yellow&quot;, &quot;green&quot;) fk_data &lt;- data.frame(size = sample(set_1, 20, replace = TRUE, prob = prob_1), weight = sample(set_2, 20, replace = TRUE, prob = prob_2), color = sample(set_3, 20, replace = TRUE)) tally_5 &lt;- fk_data %&gt;% group_by(size) %&gt;% summarise(n = n_distinct(weight, color)) print.data.frame(tally_5) ## size n ## 1 long 4 ## 2 medium 5 ## 3 short 5 "],["how-to-join-two-data-tables.html", "9 How to join two data tables", " 9 How to join two data tables In my opinion, the need to join two data tables together, is one of indicators (of course there are others) that we are dealing with complex data analysis. In practice, sometimes we may need to join many, say five, or even ten tables together. Hadley Wickham's dplyr package provides left_join(), right_join(), inner_join(), full_join(), semi_join() and anti_join(); among them, the most useful one probably is left_join(). Let me quote a couple of sentences from R for Data Science (by Garrett Grolemund and Hadley Wickham), The most commonly used join is the left join: you use this whenever you look up additional data from another table, because it preserves the original observations even when there isnt a match. The left join should be your default join: use it unless you have a strong reason to prefer one of the others. The syntax for left_join() is left_join(table_1, table_2, by = c(&quot;ID_1&quot; = &quot;ID_2&quot;)) The key point to keep in mind is that table_1 is to the left of table_2, which means table_1 is the main table, or to be more exact, which means all the rows and columns of table_1 will be kept. Let's have an example. Example. rm(list = ls()) # load packages library(dplyr) # create a fake data sets table_1 &lt;- data_frame(ID_1 = LETTERS[1:6], x = rep(1:3, each = 2)) table_2 &lt;- data_frame(ID_2 = c(LETTERS[1:3], LETTERS[7:8], &quot;A&quot;, &quot;B&quot;), y = 1:7) # join tables 1 and 2 table_3 &lt;- left_join(table_1, table_2, by = c(&quot;ID_1&quot; = &quot;ID_2&quot;)) # shwo the three tables list(table_1, table_2, table_3) ## [[1]] ## # A tibble: 6 x 2 ## ID_1 x ## &lt;chr&gt; &lt;int&gt; ## 1 A 1 ## 2 B 1 ## 3 C 2 ## 4 D 2 ## 5 E 3 ## 6 F 3 ## ## [[2]] ## # A tibble: 7 x 2 ## ID_2 y ## &lt;chr&gt; &lt;int&gt; ## 1 A 1 ## 2 B 2 ## 3 C 3 ## 4 G 4 ## 5 H 5 ## 6 A 6 ## 7 B 7 ## ## [[3]] ## # A tibble: 8 x 3 ## ID_1 x y ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 A 1 1 ## 2 A 1 6 ## 3 B 1 2 ## 4 B 1 7 ## 5 C 2 3 ## 6 D 2 NA ## 7 E 3 NA ## 8 F 3 NA Exercises. Redo the above Example to recreate table_3 but using right_join. Try inner_join() and semi_join() on table_1 and table_2 in the above example, and observe the difference between the two resulted tables. Try full_join() on table_1 and table_2 in the above example. Try anti_join() on table_1 and table_2 in the above example. Answer to the exercises: rm(list = ls()) # load packages library(dplyr) # create a fake data sets table_1 &lt;- data_frame(ID_1 = LETTERS[1:6], x = rep(1:3, each = 2)) table_2 &lt;- data_frame(ID_2 = c(LETTERS[1:3], LETTERS[7:8], &quot;A&quot;, &quot;B&quot;), y = 1:7) # Exercise 1 table_3 &lt;- table_2 %&gt;% right_join(table_1, by = c(&quot;ID_2&quot; = &quot;ID_1&quot;)) %&gt;% # change the order of columns select(ID_2, x, y) # Exercise 2 table_4 &lt;- inner_join(table_1, table_2, by = c(&quot;ID_1&quot; = &quot;ID_2&quot;)) table_5 &lt;- semi_join(table_1, table_2, by = c(&quot;ID_1&quot; = &quot;ID_2&quot;)) # Exercise 3 table_6 &lt;- full_join(table_1, table_2, by = c(&quot;ID_1&quot; = &quot;ID_2&quot;)) # Exercise 4 table_7 &lt;- anti_join(table_1, table_2, by = c(&quot;ID_1&quot; = &quot;ID_2&quot;)) # show tables 4 to 7 list(table_4, table_5, table_6, table_7) "],["how-to-plot-data.html", "10 How to plot data 10.1 Creating basic bar charts 10.2 Creating side-by-side and stacked bar charts 10.3 Creating back-to-back bar charts 10.4 Creating Pareto charts 10.5 Creating lollipop charts 10.6 Creating treemaps 10.7 Creating scatter plots 10.8 Creating side-by-side box plots 10.9 Creating grid plots 10.10 Creating a simple PCA plot 10.11 Creating time series plots 10.12 Showing pop-up's 10.13 Putting plots in one panel", " 10 How to plot data How to plot data? This is a big question, and here I can give a quick/brief answer, which is this two-step procedure. Step 1: Get the data ready. Step 2: Use ggplot2 package (or another package, e.g. treemap package, for some a specific plot). In the following 13 sections, I will use examples to illustrate the two-step procedure. 10.1 Creating basic bar charts Essentially, a basic bar chart is a plot of a categorical variable on x-axis and a numerical variable on y-axis. Example 1: a basic bar chart. rm(list = ls()) # load packages library(ggplot2) # prepare a dataframe for plotting fruits &lt;- c(&quot;apple&quot;, &quot;orange&quot;, &quot;banana&quot;) the_fruits &lt;- sample(fruits, 100, replace = TRUE) plotting_df &lt;- as.data.frame.table(table(the_fruits)) # plotting p &lt;- ggplot(plotting_df, aes(x = the_fruits, weight = Freq)) + # NB: use &quot;weight = Freq&quot; instead of &quot;y = Freq&quot; geom_bar(width = 0.5, fill = &quot;blue&quot;) + # NB: use &quot;width&quot; and &quot;fill&quot; to change the default bar width and color labs(x = &quot;&quot;, y = &quot;Frequency&quot;, title = &quot;A basic bar chart for a basket of fruits&quot;) + theme(plot.title = element_text(hjust = 0.5)) + # NB: use theme to center the title geom_text(aes(x = the_fruits, y = Freq + 1, label = Freq)) # NB: use &quot;geom_text&quot; to put the the numbers to indicate heights of bars print(p) Example 2: still a basic bar chart but making the bars horizontal and based on percentage rm(list = ls()) # load packages library(ggplot2) library(dplyr) # prepare a dataframe for plotting fruits &lt;- c(&quot;apple&quot;, &quot;orange&quot;, &quot;banana&quot;, &quot;pear&quot;, &quot;plum&quot;, &quot;kiwi fruit&quot;, &quot;peach&quot;, &quot;mango&quot;, &quot;lemon&quot;) the_fruits &lt;- sample(fruits, 1000, replace = TRUE) a_table &lt;- table(the_fruits) plotting_df &lt;- as.data.frame.table(a_table) %&gt;% mutate(proportion = Freq / sum(Freq)) ## Create a vector to order the fruits in terms of proportion for_sorting &lt;- plotting_df %&gt;% arrange(proportion) fruits_order &lt;- for_sorting$the_fruits # plotting p &lt;- ggplot(plotting_df, aes(x = the_fruits, weight = proportion)) + # NB: use &quot;weight = proportion&quot; instead of &quot;y = proportion&quot; geom_bar(width = 0.5, fill = &quot;blue&quot;) + # NB: use &quot;width&quot; and &quot;fill&quot; to change the default bar width and color labs(x = &quot;&quot;, y = &quot;&quot;, title = &quot;A &#39;horizontal&#39; bar chart for a basket of fruits&quot;) + coord_flip() + # NB: use &quot;coord_flip&quot; to flip coordinates scale_x_discrete(limits = fruits_order) + # NB: use the above to set the order of bars scale_y_continuous(limits = c(0, max(plotting_df$proportion)+0.015)) + # NB: use the above to make the plot slightly bigger than the default one geom_text(aes(x = the_fruits, y = proportion + 0.006, label = scales::percent(proportion))) + # NB: use the above to put the the pentage numbers to indicate lengths of bars theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_blank(), axis.ticks = element_blank()) # NB: use theme to center the title, to remove axis text and ticks print(p) 10.2 Creating side-by-side and stacked bar charts Example 3 rm(list = ls()) # load packages library(ggplot2) library(dplyr) #------------------- # Aim: To plot numbers of all kinds of fruits in &quot;local&quot; and &quot;imported&quot; groups #------------------- # prepare a dataframe for plotting fruits &lt;- c(&quot;apple&quot;, &quot;orange&quot;, &quot;banana&quot;, &quot;pear&quot;, &quot;plum&quot;, &quot;kiwi fruit&quot;, &quot;peach&quot;, &quot;mango&quot;, &quot;lemon&quot;) origin &lt;- c(&quot;local&quot;, &quot;imported&quot;) a_df &lt;- data.frame(the_fruits = sample(fruits, 1000, replace = TRUE), the_origin = sample(origin, 1000, replace = TRUE)) plotting_df &lt;- a_df %&gt;% group_by(the_origin, the_fruits) %&gt;% summarise(Freq = n()) # ------------ side-by-side bar chart -------------- ## set the order of bars according to local fruits temp_df_1 &lt;- plotting_df %&gt;% filter(the_origin == &quot;local&quot;) %&gt;% arrange(Freq) the_order &lt;- temp_df_1$the_fruits ## plot a side-by-side bar chart p1 &lt;- plotting_df %&gt;% ggplot(aes(x = the_fruits, weight = Freq, fill = the_origin)) + geom_bar(position = &quot;dodge&quot;, width = 0.75) + # NB: use the above to plot bars in the certain order coord_flip() + scale_x_discrete(limits = the_order) + labs(x = &quot;&quot;, y = &quot;Number of fruits in the &#39;basket&#39;&quot;) + scale_fill_brewer(breaks=c(&quot;local&quot;, &quot;imported&quot;), palette = &quot;Set1&quot;) + # NB: use the above to change the default order and color of legend theme(legend.position = &quot;bottom&quot;, legend.title = element_blank(), axis.text = element_text(size=12), axis.title = element_text(size=14), plot.title = element_text(size=14), legend.text = element_text(size=9), panel.background = element_rect(fill = &quot;grey90&quot;)) print(p1) # ------------ stacked bar chart -------------- ## set the order according to totals temp_df_2 &lt;- a_df %&gt;% group_by(the_fruits) %&gt;% summarise(the_count = n()) %&gt;% arrange(the_count) the_order_2 &lt;- temp_df_2$the_fruits ## plot a stacked bar chart p2 &lt;- plotting_df %&gt;% ggplot(aes(x = the_fruits, y = Freq, group = the_origin, fill = the_origin)) + # NB: use &quot;y = Freq&quot; instead of &quot;weight = Freq&quot; geom_bar(stat = &quot;identity&quot;, position = &quot;stack&quot;, width = 0.75) + coord_flip() + scale_x_discrete(limits = the_order_2) + # NB: use the above to plot the bars in order labs(x = &quot;&quot;, y = &quot;Number of fruits in the &#39;basket&#39;&quot;) + scale_fill_brewer(breaks=c(&quot;local&quot;, &quot;imported&quot;), palette = &quot;Set1&quot;) + # NB: use the above to change the default order and color of legend theme(legend.position = &quot;bottom&quot;, legend.title = element_blank(), axis.text = element_text(size=12), axis.title = element_text(size=14), plot.title = element_text(size=14), legend.text = element_text(size=9), panel.background = element_rect(fill = &quot;grey90&quot;)) print(p2) 10.3 Creating back-to-back bar charts Example 4 rm(list = ls()) # load packages library(dplyr) library(ggplot2) # create a fake data set ## some preparation set.seed(123) ten_positive_rand_numbers &lt;- abs(rnorm(10)) + 0.1 the_prob &lt;- ten_positive_rand_numbers / sum(ten_positive_rand_numbers) fk_data &lt;- data.frame(job_type = sample(LETTERS[1:10], 1000, replace = TRUE, prob = the_prob), gender = sample(c(&quot;Male&quot;, &quot;Female&quot;), 1000, replace = TRUE)) # prepare data for plotting plotting_df &lt;- fk_data %&gt;% group_by(job_type, gender) %&gt;% summarise(Freq = n()) %&gt;% # a trick! mutate(Freq = if_else(gender == &quot;Male&quot;, -Freq, Freq)) ## find the order temp_df &lt;- plotting_df %&gt;% filter(gender == &quot;Female&quot;) %&gt;% arrange(Freq) the_order &lt;- temp_df$job_type # plot p &lt;- plotting_df %&gt;% ggplot(aes(x = job_type, y = Freq, group = gender, fill = gender)) + geom_bar(stat = &quot;identity&quot;, width = 0.75) + coord_flip() + scale_x_discrete(limits = the_order) + # another trick! scale_y_continuous(breaks = seq(-150, 150, 50), labels = abs(seq(-150, 150, 50))) + labs(x = &quot;Job type&quot;, y = &quot;Count&quot;, title = &quot;Back-to-back bar chart&quot;) + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank(), plot.title = element_text(hjust = 0.5), panel.background = element_rect(fill = &quot;grey90&quot;)) + # reverse the order of items in legend # guides(fill = guide_legend(reverse = TRUE)) + # change the default colors of bars scale_fill_manual(values=c(&quot;red&quot;, &quot;blue&quot;), name=&quot;&quot;, breaks=c(&quot;Male&quot;, &quot;Female&quot;), labels=c(&quot;Male&quot;, &quot;Female&quot;)) print(p) Remark: We can use scale_x_discrete(limits = rev(the_order)) to replace scale_x_discrete(limits = the_order) and the resulted chart is also called pyramid chart. If you google &quot;population pyramid&quot; you can find more examples of pyramid charts. 10.4 Creating Pareto charts A Pareto chart basically is a bar chart (with the bars ordered) plus a frequency polygon (i.e. a line chart). It is useful for revealing something like the 80-20 rule---e.g. 80% of the accidents are due to 20% of the possible reasons. See https://en.wikipedia.org/wiki/Pareto_chart for more details. The following example shows how to make a Pareto chart. Please pay attention to how the layers are built up. Example 5 rm(list = ls()) # load packages library(dplyr) library(ggplot2) # create a fake data set reasons &lt;- c(&quot;Reason A&quot;, &quot;Reason B&quot;, &quot;reason C&quot;, &quot;Reason D&quot;, &quot;Reason E&quot;, &quot;reason F&quot;) set_prob &lt;- c(0.1, 0.2, 0.6, 0.05, 0.02, 0.03) fk_data &lt;- data.frame(accident_NO = 1:1000, reason = sample(reasons, 1000, replace = TRUE, prob = set_prob)) # prepare the data for plotting plotting_df &lt;- fk_data %&gt;% group_by(reason) %&gt;% summarise(freq = n()) %&gt;% arrange(desc(freq)) %&gt;% mutate(relative_freq = freq / sum(freq), cumulative_freq = cumsum(relative_freq)) ## get the order of bars the_order &lt;- plotting_df$reason # plot p &lt;- plotting_df %&gt;% ggplot(aes(x = reason, weight = relative_freq)) + geom_bar(width = 0.5, fill = &quot;blue&quot;) + scale_x_discrete(limits = the_order) + scale_y_continuous(label = scales::percent) + geom_point(aes(x = reason, y = cumulative_freq)) + geom_line(aes(x = reason, y = cumulative_freq, group = 1)) + # NB: Must use &quot;group = 1&quot; labs(x = &quot;&quot;, y = &quot;Relative frequency&quot;, title = &quot;A Pareto diagram for reasons of 1000 accidents&quot;) + theme(plot.title = element_text(hjust = 0.5)) # NB: Use theme to center the title print(p) 10.5 Creating lollipop charts Notice that \\[ \\hbox{a lollipo} = \\hbox{a segment} + \\hbox{a point}, \\] thus it is natural to use geom_segment() and geom_point() to create lollipop charts. Example 6 rm(list = ls()) library(ggplot2) library(dplyr) # create a fake data set set.seed(9072017) rand_numbers &lt;- abs(rnorm(26)) the_prob &lt;- rand_numbers/sum(rand_numbers) fk_data &lt;- data.frame(x = sample(LETTERS, 10000, replace = TRUE, prob = the_prob)) # prepare data for plotting plotting_df &lt;- fk_data %&gt;% group_by(x) %&gt;% summarise(Freq = n()) %&gt;% mutate(proportion = Freq/sum(Freq)) %&gt;% arrange(proportion) the_order &lt;- plotting_df$x # plotting p &lt;- plotting_df %&gt;% ggplot(aes(x = x, y = proportion)) + geom_segment(aes(x = x, xend = x, y = 0, yend = proportion)) + # use the above to plot segments geom_point() + # use the above to plot points scale_x_discrete(limits = the_order) + scale_y_continuous(labels = scales::percent) + labs(x = &quot;Category&quot;, y = &quot;Proportion&quot;, title = &quot;A lollipop chart&quot;) + theme(plot.title = element_text(hjust = 0.5)) # use the above to center the title print(p) 10.6 Creating treemaps A treepmap can show three variables by using lables, sizes of rectangles and colors. Below is a treemap of the top 15 NZ's most populous cities based on the 2016 data. The original data comes from: https://en.wikipedia.org/wiki/List_of_cities_in_New_Zealand Example 7 rm(list = ls()) # load packages library(treemap) library(readr) # for read_csv # read data in the_url &lt;- &quot;https://raw.githubusercontent.com/LarryZhang2016/Data/master/NZ_cities.csv&quot; NZ_cities &lt;- read_csv(the_url, skip =1) # make a tree map treemap(dtf = NZ_cities, index=c(&quot;City_name&quot;), vSize=&quot;Population&quot;, vColor=&quot;Population_density&quot;, palette=&quot;Spectral&quot;, type=&quot;value&quot;, border.col=c(&quot;grey70&quot;, &quot;grey90&quot;), fontsize.title = 18, algorithm=&quot;pivotSize&quot;, title =&quot;Treemap of the top 15 NZ&#39;s most populous cities&quot;, title.legend=&quot;Population density (people/km^2)&quot;) 10.7 Creating scatter plots A scatter plot is very useful for exploring the relationship between two continuous variables. With the following example, we show how to create a scatter plot. We want to emphasize the details, that is, label properly mark the outliers add in the regression line refit data and add in the new regression line Example 8 rm(list = ls()) # load packages library(readr) # for read_csv library(ggplot2) # read data in the_url &lt;- &quot;https://raw.githubusercontent.com/LarryZhang2016/Data/master/NZ_cities.csv&quot; NZ_cities &lt;- read_csv(the_url, skip =1) p1 &lt;- ggplot(NZ_cities, aes(x = Area_in_km2, y = Population)) + geom_point() + scale_y_continuous(labels = scales::comma) + # NB: use the above to mark large numbers labs(x = &quot;Area (in km^2)&quot;, title = paste0(&quot;Population vs. area for the \\n&quot;, &quot;top 15 NZ&#39;s most populous cities&quot;)) + # NB: use paste0 to break a long line to two lines theme(plot.title = element_text(hjust = 0.5)) print(p1) # Next, we want to label the points for # Auckland, Wellington, Christchurch, and Hamilton with their names and red # Also, add the regression line in # load packages library(dplyr) library(ggrepel) # for geom_text_repel() # add two new columns to NZ_cities biggest_cities &lt;- c(&quot;Auckland&quot;, &quot;Wellington&quot;, &quot;Christchurch&quot;,&quot;Hamilton&quot;) NZ_cities_1 &lt;- NZ_cities %&gt;% mutate(the_label = if_else(City_name %in% biggest_cities, City_name, &quot;&quot;), the_color = if_else(City_name %in% biggest_cities, &quot;red&quot;, &quot;black&quot;)) p2 &lt;- p1 + geom_text_repel(data = NZ_cities_1, aes(label = the_label)) + geom_point(color = NZ_cities_1$the_color) + # add in the regression line geom_smooth(method = &quot;lm&quot;, se = FALSE) print(p2) # Finally, refit the data after removing &quot;Auckland&quot;, &quot;Wellington&quot;, &quot;Christchurch&quot; # add in the new regression line NZ_cities_2 &lt;- NZ_cities %&gt;% filter(!(City_name %in% biggest_cities[1:3])) %&gt;% select(City_name, Population, Area_in_km2) ## find the regression equtions line_1 &lt;- lm(Population ~ Area_in_km2, NZ_cities) line_2 &lt;- lm(Population ~ Area_in_km2, NZ_cities_2) line_1_eq &lt;- paste0(&quot;Line 1: &quot;, &quot;Population = &quot;, round(line_1[[1]][1], 2), &quot; + &quot;, round(line_1[[1]][2], 2), &quot; * Area&quot;) line_2_eq &lt;- paste0(&quot;Line 2: &quot;, &quot;Population = &quot;, round(line_2[[1]][1], 2), &quot; + &quot;, round(line_2[[1]][2], 2), &quot; * Area&quot;) p3 &lt;- p1 + geom_text_repel(aes(label = NZ_cities_1$the_label)) + geom_point(color = NZ_cities_1$the_color) + # add in the regression line geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;blue&quot;) + geom_smooth(data = NZ_cities_2, method = &quot;lm&quot;, se = FALSE, color = &quot;purple&quot;) + annotate(geom = &quot;text&quot;, x = 400, y = 1400000, label=line_1_eq, color=&quot;blue&quot;) + annotate(geom = &quot;text&quot;, x = 400, y = 1250000, label=line_2_eq, color=&quot;purple&quot;) print(p3) 10.8 Creating side-by-side box plots Roughly speaking, a box plot shows the five-number summary---i.e. minimum, first quartile, second quartile, third quartile, and maximum---of data. Plotting several box plots together, we have the so-called side-by-side box plot, which is useful for comparison of data among groups. In the following example, we will create a side-by-side box plot for random numbers drawn from the standard normal distribution, the t distribution with five degrees of freedom, the uniform distribution on \\((-3, 3)\\), and the double exponential distribution with the probability density \\[ f(y)=\\frac{1}{2}\\lambda e ^{-\\lambda |y|}\\ \\hbox{for}\\ -\\infty &lt;y&lt;+\\infty, \\] where \\(\\lambda=\\sqrt{\\frac{2}{\\pi}}\\). For our purpose, we need this Technical note: We can show that if \\(X\\sim \\hbox{Exp}(\\lambda)\\), \\(U\\sim \\hbox{Uniform}(0, 1)\\), and \\(X\\) and \\(U\\) are independent, then \\[ Y=\\left\\{ \\begin{array}{rl} -X, &amp; \\hbox{if}\\ U\\le 0.5,\\\\ X, &amp; \\hbox{if}\\ U &gt; 0.5, \\end{array} \\right. \\] has a double exponential distribution; that is, the probability density function of \\(Y\\) is \\[ f(y) = \\frac{\\lambda}{2}e^{-\\lambda |y|}\\ \\hbox{for}\\ -\\infty &lt; y &lt; +\\infty. \\] Example 9 rm(list = ls()) # load packages library(dplyr) library(tidyr) # for gather() library(ggplot2) # create a fake data set set.seed(1234567) fk_data &lt;- data.frame(Normal = rnorm(1000), t_df_5 = rt(1000, df = 5), Unif = runif(1000, -3, 3), Exp = rexp(1000, rate = sqrt(2/pi)), Unif_temp = runif(1000, 0, 1)) %&gt;% mutate(the_indi = if_else(Unif_temp &lt;= 0.5, -1, 1)) %&gt;% mutate(Double_exp = Exp * the_indi) %&gt;% select(-Exp, -Unif_temp, -the_indi) # prepare data for plotting plotting_df &lt;- fk_data %&gt;% gather(key = distribution, value = rand_number, Normal:Double_exp) # plot p &lt;- plotting_df %&gt;% ggplot(aes(x = distribution, y = rand_number, group = distribution)) + geom_boxplot() + coord_flip() + scale_x_discrete(breaks = c(&quot;Double_exp&quot;, &quot;Normal&quot;, &quot;t_df_5&quot;, &quot;Unif&quot;), labels = c(&quot;Double Exponential&quot;, &quot;Standard Normal&quot;, &quot;t with df=5&quot;, &quot;Uniform on (-3, 3)&quot;)) + # NB: use the above to change x-axis tick marks labs(x = &quot;Distribution&quot;, y = &quot;&quot;, title = &quot;Side-by-side box plot&quot;) + theme(plot.title = element_text(hjust = 0.5)) print(p) 10.9 Creating grid plots Grid plots allow us to show several (e.g. four) variables in one plot, and certainly they are useful. The key here is to use facet_grid(). Example 10 rm(list = ls()) # load packages library(dplyr) library(tidyr) library(ggplot2) # create a fake data set ## a helper function set.seed(21072017) create_year_data &lt;- function(year = 2015, n = 20) {temp_df &lt;- data.frame(year = rep(year, n), gender = sample(c(&quot;male&quot;, &quot;female&quot;), n, replace = TRUE), stats_grade = rnorm(n, mean = 55, sd = 10), math_grade = rnorm(n, mean = 60, sd = 10)) return(temp_df) } data_2016 &lt;- create_year_data(year = 2016, n = 20) data_2015 &lt;- create_year_data(year = 2015, n = 20) data_2014 &lt;- create_year_data(year = 2014, n = 20) fk_data &lt;- bind_rows(data_2016, data_2015, data_2014) # prepare data for plotting plotting_df &lt;- fk_data %&gt;% group_by(year, gender) %&gt;% summarise(Stats = mean(stats_grade), Maths = mean(math_grade)) %&gt;% ungroup() %&gt;% # make a long table gather(key = subject, value = grade, -year, -gender) %&gt;% arrange(year) # plot the_title &lt;- paste0(&quot;Averge maths and stats grades for\\n&quot;, &quot;female and male students in 2014-2016&quot;) p &lt;- plotting_df %&gt;% ggplot(aes(y = grade, color = gender)) + geom_segment(aes(x = gender, xend = gender, y = 0, yend = grade)) + geom_point(aes(x = gender, y = grade)) + coord_flip() + scale_x_discrete(limits = c(&quot;male&quot;, &quot;female&quot;)) + facet_grid(year ~ subject) + labs(x = &quot;&quot;, y = &quot;Average Grade&quot;, title = the_title) + theme(plot.title = element_text(hjust = 0.5), legend.title = element_blank(), panel.background = element_rect(fill = &quot;grey90&quot;)) print(p) 10.10 Creating a simple PCA plot When we have an \\(n\\)-variate (\\(n\\ge 3\\)) data set, where each column contains continuous type data, we often want to look at the cluster relationship among the \\(m\\) observations (or rows). For this purpose. we can make a PCA (Principal Component Analysis) plot. The fundamental idea here is that we map the \\(n\\)-dimension data to 2-dimension (PC1 and PC2) data and then make a scatter plot of the 2-dimension data. Example 11 rm(list=ls()) # load packages library(dplyr, quietly = TRUE) library(ggplot2, quietly = TRUE) # NB: We will use iris, which is a data set from R (head(iris)) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa # do the mapping ## step 1: find the covariance the_cov &lt;- cov(iris[, 1:4]) ## step 2: find the eigen values and vectors the_eigen &lt;- eigen(the_cov) ## Remark: steps 1 and 2 together is equivalent to ## PC &lt;- prcomp(iris[, 1:4]) ## step 3: mapping map_2_PC1_PC2 &lt;- as.matrix(iris[,1:4]) %*% the_eigen[[2]][, 1:2] %&gt;% as.data.frame() # check how much variance are expressed by PC1 and PC2 (the_proportions = the_eigen[[1]][1:2]/sum(the_eigen[[1]])) ## [1] 0.92461872 0.05306648 # prepare dataframe for plotting temp_df &lt;- data.frame(Species = iris[, 5]) plotting_df &lt;- bind_cols(map_2_PC1_PC2, temp_df) %&gt;% rename(PC1 = V1, PC2 = V2) # plotting ggplot(plotting_df, aes(x = PC1, y = PC2, color = Species)) + geom_point() 10.11 Creating time series plots It is easy to create a time series plot. Here we pay attention to some &quot;small&quot; things. Make sure the time is labelled correctly on x-axis. If the values are for money and large, then we should show the $ sign and use &quot;,&quot; in the numbers for labeling y-axis. We often want to get the points connected to show that the points are related. Example 12 rm(list = ls()) # load packages library(ggplot2) library(lubridate) # for dealing with data related to time # create a fake data set for_year &lt;- 1997:2016 for_month &lt;- rep(12, 20) for_day &lt;- rep(31, 20) col_1 &lt;- paste0(for_year, &quot;-&quot;, for_month, &quot;-&quot;, for_day) col_2 &lt;- rep(0, 20) ## simulated data from a random walk set.seed(20170805) epsilon &lt;- rnorm(20, mean = 0, sd = 10000) x0 &lt;- 5*1e5 for(i in 1:20) {col_2[i] &lt;- x0 + epsilon[i] x0 &lt;- col_2[i] } fk_data &lt;- data.frame(EndOfYear = ymd(col_1), Value_in_dollar = round(col_2, 0)) # plot data p &lt;- ggplot(fk_data, aes(x = year(EndOfYear), y = Value_in_dollar)) + # Note the use of function year() geom_point() + geom_line() + scale_y_continuous(labels = scales::dollar) + labs(x = &quot;Year&quot;, y = &quot;Market value&quot;, title = &quot;Plot of a time series&quot;) + theme(plot.title = element_text(hjust = 0.5)) print(p) 10.12 Showing pop-up's For exploratory data analysis, we may want our plot to have such a feature, which is when we hover the mouse on the plot some information will pop up. In the following example, I will show how to do it with plotly::ggplotly() (thanks to Chris Hansen for pointing this function to me.) Of course there are other useful R packages available for showing pop-up's, such as googleVis and highcharter, if having an interest the readers can explore them. Example 13 rm(list = ls()) # load packages library(readr) # for read_csv library(ggplot2) library(plotly) # read data in the_url &lt;- &quot;https://raw.githubusercontent.com/LarryZhang2016/Data/master/NZ_cities.csv&quot; NZ_cities &lt;- read_csv(the_url, skip =1) p1 &lt;- ggplot(NZ_cities, aes(x = Area_in_km2, y = Population, fill = City_name, text = paste0(&#39;City: &#39;, City_name, &#39;&lt;br&gt;Area (in km^2): &#39;, Area_in_km2, &#39;&lt;br&gt;Population: &#39;, Population ))) + geom_point() + scale_y_continuous(labels = scales::comma) + # NB: use the above to mark large numbers labs(x = &quot;Area (in km^2)&quot;, y = &quot;Population Size&quot;, title = paste0(&quot;Population vs. area for the top 15\\n&quot;, &quot;NZ&#39;s most populous cities&quot;)) + # NB: use paste0 to break a long line to two lines theme(plot.title = element_text(hjust = 0.5), legend.position=&quot;none&quot;, plot.margin = unit(c(t = 1, r = 0.5, b = 0.5, l = 1.5), &quot;cm&quot;)) ggplotly(p1, tooltip = c(&quot;text&quot;)) %&gt;% config(displayModeBar = FALSE) 10.13 Putting plots in one panel We create a few plots and want to put them together. It is handy to do so with gridExtra::grid.arrange(). (I thank Peter Ellis for pointing me to this function.) Example 14 rm(list = ls()) # load packages library(gridExtra) library(ggplot2) # a function for plotting probability density functions plot_density &lt;- function(func_name = dnorm, para = list(mean=0, sd=1), domain = data.frame(x = c(-3, 3)), title_lable = &quot;PDF of N(0, 1)&quot;) {p &lt;- ggplot(domain, aes(x)) + stat_function(fun = func_name, args = para, color = &quot;red&quot;) + labs(x = &quot;x&quot;, y = &quot;f(x)&quot;, title = title_lable) + theme(plot.title = element_text(hjust = 0.5)) # make the title in center return(p) } # plot four probability density functions p1 &lt;- plot_density() p2 &lt;- plot_density(func_name = dt, para = list(df=30), title_lable = &quot;PDF of t distribution with df=30&quot;) p3 &lt;- plot_density(func_name = dexp, para = list(rate = 1), domain = data.frame(x = c(0, 10)), title_lable = &quot;PDF of Exp(1) distribution&quot;) p4&lt;- plot_density(func_name = dchisq, para = list(df=5), domain = data.frame(x = c(0, 10)), title_lable = &quot;PDF of Chisq distribution with df=5&quot;) # put the four plots together grid.arrange(p1, p2, p3, p4, newpage = TRUE, layout_matrix = matrix(1:4, byrow = TRUE, 2, 2)) "],["how-to-create-a-dynamic-report.html", "11 How to create a dynamic report", " 11 How to create a dynamic report Suppose we are requested to produce a report. This report has the following features. It is based on data collected quarterly (or annually). That is, this is a report that provides the context and summarises the data with texts, numbers, graphs and tables. The report must be quickly updated when the new quarterly (or annually) data are available---this is a dynamic report. How to create such a report? The short answer is that we can use the Knitr package to do it. The workflow is shown below. Create a new project, called e.g. DynamicReport in Rstudio, and then create subfolders: Data, R, Figures, Tables, Knitr, Output Save raw data in the Data folder. Write R programs and save them in the R folder. The R programs are for data analysis, such as tidying up the data (if necessary), creating graphs (the created graphs will be saved in the Figures folder), tables (will be saved in the Tables folder in TEX format) and numbers (will be saved in an Rdata file which will be in an automatically created sub-folder called &quot;cache&quot; under the R folder). Prepare Report.Rnw file, which will be saved in the Knitr folder. Create integrate.R (under the project folder) to produce the report. Following the above workflow, I have done an example called &quot;dynamic_report&quot;, and this example can be downloaded from my GitHub page https://github.com/LarryZhang2016 "],["how-to-learn-shiny.html", "12 How to learn Shiny", " 12 How to learn Shiny It's cool if we can make shiny apps, and sometimes we are asked to make a shiny app at work. So, we do want and need to learn the Shiny package. The question is: How can we quickly learn it? I don't think there is the best answer to this question, because we all have different learning styles and &quot;one man's meat is [possibly] another man's poison.&quot; Here, based on my learning experience, just tell you how I learned the Shiny stuff; it's only for your reference. I watched the three webinars presented by Garrett Grolemund a few times; the links are: https://www.rstudio.com/resources/webinars/how-to-start-with-shiny-part-1/ https://www.rstudio.com/resources/webinars/how-to-start-with-shiny-part-2/ https://www.rstudio.com/resources/webinars/how-to-start-with-shiny-part-3/ I watched Winston Chang's webinar (https://www.rstudio.com/resources/webinars/dynamic-dashboards-with-shiny/) a couple of times. Practice, using this template library(shiny) ui &lt;- fluidPage( xxxxInput(), xxxxOutput() ) server &lt;- function(input, output) { R code } shinyApp(ui = ui, server = server) for example, library(shiny) ui &lt;- fluidPage( titlePanel(title = &quot;Shiny Exercise&quot;), sidebarPanel(width = 4, sliderInput(&quot;RandNum&quot;, label = &quot;choose a number&quot;, value = 20, min = 10, max = 100) ), mainPanel(wideth = 8, plotOutput(&quot;scatter&quot;)) ) server &lt;- function(input, output) {output$scatter &lt;- renderPlot({ x &lt;- rnorm(input$RandNum) y &lt;- rnorm(input$RandNum) plot(x, y, xlab = &quot;x&quot;, ylab = &quot;y&quot;, main = &quot;Scatter plot&quot;) }) } shinyApp(ui = ui, server = server) Below is a screenshot I made several small apps and published them on https://www.shinyapps.io/ e.g. see these three: https://larryzhang.shinyapps.io/histogramorboxplot/, https://larryzhang.shinyapps.io/distributions/, and https://larryzhang.shinyapps.io/city_map/ "],["how-to-make-a-simple-data-dictionary.html", "13 How to make a simple data dictionary", " 13 How to make a simple data dictionary Inspired by Dania M. Rodriguez (https://cran.r-project.org/web/packages/dataMeta/vignettes/dataMeta_Vignette.html), I wrote an R function data_dic_builder() for making simple data dictionaries. Explanations: Output the output is a dataframe having two columns column 1 has the names of data variables column 2 has the number of unique values of each variable if it is not an interesting one, or the unique values of each variable if it is an interesting one Arguments 'df' is a dataframe which contains the data 'variable_type' is a vector which contains 0 or 1. 0 means we are not interested in this variable; 1 means that we have an interest in this variable Example: # a function for making simple data dictionaries -------------------------- data_dic_builder &lt;- function(df, variable_type) {df &lt;- as.data.frame(df) # make sure df is a dataframe n &lt;- dim(df)[2] length_of_uniq_var &lt;- rep(0, n) length_of_uniq_var_1 &lt;- rep(0, n) for(i in 1:n) {length_of_uniq_var[i] &lt;- length(unique(df[, i])) length_of_uniq_var_1[i] &lt;- ifelse(variable_type[i] == 0, 1, length_of_uniq_var[i]) } m &lt;- sum(variable_type * length_of_uniq_var) + sum(variable_type == 0) long_list_1 &lt;- rep(&quot;&quot;, m) long_list_2 &lt;- rep(&quot;&quot;, m) the_var_names &lt;- names(df) the_cum_length &lt;- cumsum(length_of_uniq_var_1) for(i in 1:n) {if(length_of_uniq_var_1[i] == 1) {temp_char_1 &lt;- the_var_names[i] temp_char_2 &lt;- as.character(length_of_uniq_var[i]) } else {temp_char_1 &lt;- c(the_var_names[i], rep(&quot;&quot;, length_of_uniq_var_1[i] - 1)) temp_char_2 &lt;- as.character(unique(df[, i]))} start_point &lt;- ifelse(i==1, 1, the_cum_length[i-1] + 1) end_point &lt;- the_cum_length[i] long_list_1[start_point:end_point] &lt;- temp_char_1 long_list_2[start_point:end_point] &lt;- temp_char_2 } output_df &lt;- data.frame(Var_name = long_list_1, Unique_n_or_unique_values = long_list_2) return(output_df) } # a test example ---------------------------------------------------------- ## create a fake data set color_set &lt;- c(&quot;red&quot;, &quot;green&quot;, &quot;blue&quot;) fk_data &lt;- data.frame(x = rnorm(100), type = sample(LETTERS[1:5], 100, replace = TRUE), corlor = sample(color_set, 100, replace = TRUE), y = runif(100)) my_dic &lt;- data_dic_builder(df = fk_data, variable_type = c(0, 1, 1, 0)) print(my_dic) ## Var_name Unique_n_or_unique_values ## 1 x 100 ## 2 type D ## 3 C ## 4 B ## 5 E ## 6 A ## 7 corlor red ## 8 green ## 9 blue ## 10 y 100 "],["how-to-check-code-efficiency.html", "14 How to check code efficiency", " 14 How to check code efficiency At some point, we may feel frustrated about our code---it takes so long to run! Generally speaking, it is a difficult task to make our code very efficient, but it is easy to find the elapsed time of code running and the bottleneck(s). The tool that we can use is: library(profvis) profvis({R code}) Example: library(profvis) profvis({ x &lt;- rnorm(10e8) total_1 &lt;- 0 for(i in 1:10e8) total_1 &lt;- total_1 + x[i] total_2 &lt;- sum(x) list(total_1, total_2) }) As expected, the above analysis shows that the bottleneck is at the &quot;for loop&quot;. For more details, please watch Winston Chang's webinar https://www.rstudio.com/resources/webinars/profvis-profiling-tools-for-faster-r-code/ and his another talk https://www.rstudio.com/resources/videos/profiling-and-performance/ "],["how-to-create-a-package.html", "15 How to create a package 15.1 What is an R package? 15.2 Two handy tools 15.3 The procedure", " 15 How to create a package 15.1 What is an R package? An R package is a folder that contains required files and sub-folders. In RStudio, it is easy to create an R package. 15.2 Two handy tools devtools roxygen2 15.3 The procedure Step 1: Create the &quot;structure&quot;, which is an empty folder containing required although empty sub-folders and files, in RStudio. file&gt;new project...&gt;package Step 2: Write R files and save them in the R folder. An example: #&#39; find key information about a dataframe #&#39; #&#39; This function allows you to find key information about a dataframe #&#39; @param a_df a dataframe #&#39; @keywords key info; dataframe #&#39; @export #&#39; @author Lingyun (Larry) Zhang \\email{lyzhang10@gmail.com} #&#39; @examples #&#39; temp_df &lt;- #&#39; data.frame(a = 1:10, #&#39; b = NA, #&#39; e = c(letters[1:8], NA, NA)) #&#39; x &lt;- find_df_key_info(temp_df) #&#39; @importFrom magrittr %&gt;% find_df_key_info &lt;- function(a_df) {re_df &lt;- data.frame(vari_names = names(a_df)) %&gt;% dplyr::mutate(type = purrr::map_chr(a_df, typeof), no_of_unique_rows = purrr::map_int(a_df, function(x) length(unique(x))), no_of_rows = dim(a_df)[1], no_of_NAs = purrr::map_int(a_df, function(x) sum(is.na(x)))) return(re_df) } Step 3: Run the following R code library(devtools) library(roxygen2) document() Step 4: Work on DESCRIPTION file. An example: Package: dfexplorer Type: Package Title: &#39;dfexplorer&#39; for explore new dataframe Version: 0.1.0 Author: Lingyun (Larry) Zhang Maintainer: Lingyun (Larry) Zhang &lt;lyzhang10@gmail.com&gt; Description: This package contains functions for explore &quot;new&quot; data in a dataframe Imports: dplyr, magrittr, purrr License: GPL-3 Encoding: UTF-8 LazyData: true RoxygenNote: 6.1.1 Step 5: Build the package by clicking on the Build button and ... Step 6: Version control---link to a repo in Github initialize the project. Tools&gt;Version Control&gt;... stage and commit create a repo under your Github account set up connection by clicking Git button; then clicking on the two purple boxes and a white square in the Git pane .... (Key parameters: new branch name master; remote name origin. Reference: section 17.5.3 on https://happygitwithr.com/existing-github-last.html) commit and push "],["how-to-put-n-things-in-m-boxes.html", "16 How to put n things in m boxes", " 16 How to put n things in m boxes How to put n things randomly and uniformly into m boxes, this is an interesting problem and its solution is useful for our work. There are probably many ways to solve this problem; here is my way---I will use gtools::rdirichlet() (For details about the Dirichlet distribution, see https://en.wikipedia.org/wiki/Dirichlet_distribution) R code: split_n &lt;- function(n, m) {n &lt;- as.integer(abs(n)) m &lt;- as.integer(abs(m)) if(n == 0L | m &lt; 2L) print(&quot;n must be postive and m must be larger than 2.&quot;) else {the_weights &lt;- gtools::rdirichlet(1, rep(1, m)) # Sometimes the following weighting is useful # the_weights &lt;- gtools::rdirichlet(1, abs(rnorm(m))) the_weights &lt;- as.vector(the_weights) the_split &lt;- floor(n * the_weights) # always rounding down left_number &lt;- n - sum(the_split) # randomly choose the positions where extra 1 will be added to the_split the_position &lt;- sample(1:m, left_number) the_split[the_position] &lt;- the_split[the_position] + 1 return(the_split) } } (split_n(10, 4)) ## [1] 2 0 2 6 "],["how-to-restore-lost-zeros.html", "17 How to restore lost zeros", " 17 How to restore lost zeros I had the so-called &quot;lost zeros&quot; problem before. The problem can be described like this: One column, called &quot;ID&quot;, contains n-digit (e.g. n=7) numbers; but for whatever reasons, the leading zeros are lost, e.g. &quot;0926541&quot;, &quot;0024267&quot; and &quot;0003115&quot; become &quot;926541&quot;, &quot;24267&quot; and &quot;3115&quot;, respectively. We must restore the lost zeros back and change the variable &quot;ID&quot; to characteristic type, because we will need this variable to join the data set with another data set. How to solve this problem? The major steps of my solution to this problem is as follows: 1, Write a helper function: helper_func &lt;- function(x) {m &lt;- length(x) y &lt;- rep(&quot;&quot;, m) for(i in 1:m) if(x[i] &gt; 0) y[i] &lt;- paste(rep(0, x[i]), collapse = &quot;&quot;) return(y) } Create a new variable, &quot;no_zeros&quot;, which is for the number of zeros that need to be added to each ID to make it have n digits. Note the formula is: \\[ n - \\hbox{ceiling}(\\hbox{log10}(\\hbox{ID})) \\] Use dplyr::mutate() and helper_func() to create a new column, &quot;the_zeros&quot;, which contains the corresponding number of lost zeros. Use paste0() to concatenate &quot;the_zeros&quot; and &quot;ID&quot; and then assign to &quot;ID&quot;. Use dplyr::select to unselect &quot;no_zeros&quot; and &quot;the_zeros&quot;. Example: rm(list=ls()) # load packages library(dplyr) # create fake data fk_data &lt;- data.frame(ID = sample(1000:9999999, 1000, replace = FALSE), d = rnorm(1000)) # a helper function helper_func &lt;- function(x) {m &lt;- length(x) y &lt;- rep(&quot;&quot;, m) for(i in 1:m) if(x[i] &gt; 0) y[i] &lt;- paste(rep(0, x[i]), collapse = &quot;&quot;) return(y) } # data manipulation fk_data &lt;- fk_data %&gt;% mutate(no_zeros = 7 - ceiling(log10(ID))) %&gt;% mutate(the_zeros = helper_func(no_zeros)) %&gt;% mutate(ID = paste0(the_zeros, ID)) %&gt;% select(-no_zeros, -the_zeros ) Remark: After I had done the above, from a colleague, I learned a much easier way to solve the problem, which is to use sprintf(). Below is the R code for re-doing the above example using sprintf(). rm(list=ls()) library(dplyr) # create fake data fk_data &lt;- data.frame(ID = sample(1000:9999999, 1000, replace = FALSE), d = rnorm(1000)) # data manipulation fk_data &lt;- fk_data %&gt;% mutate(ID = sprintf(&quot;%07d&quot;, ID)) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
